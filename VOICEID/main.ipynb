{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voice Authentication and Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import time\n",
    "from numpy import genfromtxt\n",
    "\n",
    "np.set_printoptions()\n",
    "\n",
    "import pyaudio\n",
    "from IPython.display import Audio, display, clear_output\n",
    "import wave\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn.mixture import GaussianMixture \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import python_speech_features as mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate and returns the delta of given feature vector matrix\n",
    "def calculate_delta(array):\n",
    "    rows,cols = array.shape\n",
    "    deltas = np.zeros((rows,20))\n",
    "    N = 2\n",
    "    for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while j <= N:\n",
    "            if i-j < 0:\n",
    "                first = 0\n",
    "            else:\n",
    "                first = i-j\n",
    "            if i+j > rows -1:\n",
    "                second = rows -1\n",
    "            else:\n",
    "                second = i+j\n",
    "            index.append((second,first))\n",
    "            j+=1\n",
    "        deltas[i] = ( array[index[0][0]]-array[index[0][1]] + (2 * (array[index[1][0]]-array[index[1][1]])) ) / 10\n",
    "    return deltas\n",
    "\n",
    "#convert audio to mfcc features\n",
    "def extract_features(audio,rate):    \n",
    "    mfcc_feat = mfcc.mfcc(audio,rate, 0.025, 0.01,20,appendEnergy = True, nfft=1103)\n",
    "    mfcc_feat = preprocessing.scale(mfcc_feat)\n",
    "    delta = calculate_delta(mfcc_feat)\n",
    "\n",
    "    #combining both mfcc features and delta\n",
    "    combined = np.hstack((mfcc_feat,delta)) \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a New User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Name:mohnish\n",
      "Username already exist, try another user name.\n"
     ]
    }
   ],
   "source": [
    "def add_user():\n",
    "    name = input(\"Enter Name:\")\n",
    "    #Voice authentication\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    CHUNK = 1024\n",
    "    RECORD_SECONDS = 10\n",
    "    \n",
    "    source = \"./voice_database/\" + name\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(source)\n",
    "\n",
    "\n",
    "        for i in range(3):\n",
    "            audio = pyaudio.PyAudio()\n",
    "\n",
    "            if i == 0:\n",
    "                j = 3\n",
    "                while j>=0:\n",
    "                    time.sleep(1.0)\n",
    "                    print(\"Speak your name in {} seconds\".format(j))\n",
    "                    clear_output(wait=True)\n",
    "\n",
    "                    j-=1\n",
    "\n",
    "            elif i ==1:\n",
    "                print(\"Say the pass phrase...\")\n",
    "                time.sleep(0.5)\n",
    "\n",
    "            else:\n",
    "                print(\"Say the pass phrase...\")\n",
    "                time.sleep(0.5)\n",
    "\n",
    "            # start Recording\n",
    "            stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "\n",
    "            print(\"recording...\")\n",
    "            frames = []\n",
    "\n",
    "            for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "                data = stream.read(CHUNK)\n",
    "                frames.append(data)\n",
    "\n",
    "            # stop Recording\n",
    "            stream.stop_stream()\n",
    "            stream.close()\n",
    "            audio.terminate()\n",
    "\n",
    "            # saving wav file of speaker\n",
    "            waveFile = wave.open(source + '/' + str((i+1)) + '.wav', 'wb')\n",
    "            waveFile.setnchannels(CHANNELS)\n",
    "            waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "            waveFile.setframerate(RATE)\n",
    "            waveFile.writeframes(b''.join(frames))\n",
    "            waveFile.close()\n",
    "            print(\"Done\")\n",
    "\n",
    "        dest =  \"./gmm_models/\"\n",
    "        count = 1\n",
    "\n",
    "        for path in os.listdir(source):\n",
    "            path = os.path.join(source, path)\n",
    "\n",
    "            features = np.array([])\n",
    "\n",
    "            # reading audio files of speaker\n",
    "            (sr, audio) = read(path)\n",
    "\n",
    "            # extract 40 dimensional MFCC & delta MFCC features\n",
    "            vector   = extract_features(audio,sr)\n",
    "\n",
    "            if features.size == 0:\n",
    "                features = vector\n",
    "            else:\n",
    "                features = np.vstack((features, vector))\n",
    "\n",
    "            # when features of 3 files of speaker are concatenated, then do model training\n",
    "            if count == 3:    \n",
    "                gmm = GaussianMixture(n_components = 16, max_iter = 200, covariance_type='diag',n_init = 3)\n",
    "                gmm.fit(features)\n",
    "\n",
    "                # saving the trained gaussian model\n",
    "                pickle.dump(gmm, open(dest + name + '.gmm', 'wb'))\n",
    "                print(name + ' added successfully') \n",
    "\n",
    "                features = np.asarray(())\n",
    "                count = 0\n",
    "            count = count + 1\n",
    "            \n",
    "    except:\n",
    "        print('Username already exist, try another user name.')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    add_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voice Authentication and Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording...\n",
      "finished recording\n",
      "Score for  girish  is: -22.89739365973171\n",
      "Score for  janhavi  is: -23.063866813521113\n",
      "Score for  mahima  is: -24.069592228347823\n",
      "Score for  mahimaB  is: -23.353151687374208\n",
      "Score for  mohnish  is: -23.21115665747401\n",
      "Score for  ovesh  is: -24.04333524076435\n",
      "Score for  public  is: -29.215341298766766\n",
      "Score for  purnima  is: -23.340144976407785\n",
      "Score for  shloki  is: -26.022879861114216\n",
      "Score for  supriya  is: -23.387671100914115\n",
      "Score for  unknown  is: -33.69290264613979\n",
      "Score for  unknown2  is: -28.319961181972683\n",
      "Score for  unknown3  is: -32.5875711578589\n",
      "Score for  unknown4  is: -24.375220148087074\n",
      "Score for  unknown5  is: -26.75448975135713\n",
      "Score for  vinaya  is: -23.43030783239262\n",
      "-22.89739365973171\n",
      "[ 0.          0.16647315  1.17219857  0.45575803  0.313763    1.14594158\n",
      "  6.31794764  0.44275132  3.1254862   0.49027744 10.79550899  5.42256752\n",
      "  9.6901775   1.47782649  3.85709609  0.53291417]\n",
      "10\n",
      "Not recognised try again\n"
     ]
    }
   ],
   "source": [
    "def recognize():\n",
    "    # Voice Authentication\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    CHUNK = 1024\n",
    "    RECORD_SECONDS = 10\n",
    "    FILENAME = \"./test.wav\"\n",
    "\n",
    "    audio = pyaudio.PyAudio()\n",
    "   \n",
    "    # start Recording\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"recording...\")\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    print(\"finished recording\")\n",
    "\n",
    "\n",
    "    # stop Recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # saving wav file \n",
    "    waveFile = wave.open(FILENAME, 'wb')\n",
    "    waveFile.setnchannels(CHANNELS)\n",
    "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    waveFile.setframerate(RATE)\n",
    "    waveFile.writeframes(b''.join(frames))\n",
    "    waveFile.close()\n",
    "\n",
    "    modelpath = \"./gmm_models/\"\n",
    "\n",
    "    gmm_files = [os.path.join(modelpath,fname) for fname in \n",
    "                os.listdir(modelpath) if fname.endswith('.gmm')]\n",
    "\n",
    "    models    = [pickle.load(open(fname,'rb')) for fname in gmm_files]\n",
    "\n",
    "    speakers   = [fname.split(\"/\")[-1].split(\".gmm\")[0] for fname \n",
    "                in gmm_files]\n",
    "  \n",
    "    if len(models) == 0:\n",
    "        print(\"No Users in the Database!\")\n",
    "        return\n",
    "        \n",
    "    #read test file\n",
    "    sr,audio = read(FILENAME)\n",
    "    \n",
    "    # extract mfcc features\n",
    "    vector = extract_features(audio,sr)\n",
    "    log_likelihood = np.zeros(len(models)) \n",
    "    diff=np.zeros(len(models))\n",
    "    #checking with each model one by one\n",
    "    for i in range(len(models)):\n",
    "        gmm = models[i]         \n",
    "        scores = np.array(gmm.score(vector))\n",
    "        log_likelihood[i] = scores.sum()\n",
    "        print(\"Score for \",speakers[i],\" is:\",log_likelihood[i])\n",
    "\n",
    "    pred = np.argmax(log_likelihood)\n",
    "    identity = speakers[pred]\n",
    "    print(log_likelihood[pred])\n",
    "    count=0\n",
    "    for i in range(len(models)):\n",
    "        diff[i]=log_likelihood[pred]-log_likelihood[i]\n",
    "        if diff[i]>0.75:\n",
    "            count=count+1\n",
    "    print(diff)\n",
    "    print(count)\n",
    "    # if voice not recognized than terminate the process\n",
    "    if identity == 'unknown' or identity == 'unknown2' or identity == 'unknown3' or identity == 'unknown4' or identity == 'unknown5':\n",
    "            print(\"Not Recognized! Try again...\")\n",
    "            return\n",
    "    else:\n",
    "        if count==len(models)-1:\n",
    "            print( \"Recognized as - \", identity)\n",
    "        else:\n",
    "            print( \"Not recognised try again\")\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    recognize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter name of the user:mkn\n",
      "No such user in database.\n"
     ]
    }
   ],
   "source": [
    "# deletes a registered user from database\n",
    "def delete_user():\n",
    "    try:\n",
    "        name = input(\"Enter name of the user:\")\n",
    "        # remove the speaker wav files and gmm model\n",
    "        [os.remove(path) for path in glob.glob('./voice_database/' + name + '/*')]\n",
    "        os.removedirs('./voice_database/' + name)\n",
    "        os.remove('./gmm_models/' + name + '.gmm')\n",
    "    except:\n",
    "        print('No such user in database.')\n",
    "\n",
    "delete_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
